import { generateText } from "ai";
import { auth } from "@/lib/auth";
import { getApiKey } from "@/lib/ai/get-api-key";
import { getModelWithKey } from "@/lib/ai/providers";
import { validatePrompt } from "@/lib/security/prompt-validator";

export const maxDuration = 300; // 5ë¶„ íƒ€ì„ì•„ì›ƒ

interface ResearchRequest {
  query: string;
  depth: "quick" | "standard" | "deep";
}

// SSE ìŠ¤íŠ¸ë¦¼ í—¬í¼
function createSSEStream() {
  const encoder = new TextEncoder();
  let controller: ReadableStreamDefaultController<Uint8Array>;

  const stream = new ReadableStream<Uint8Array>({
    start(c) {
      controller = c;
    },
  });

  const sendProgress = (data: object) => {
    controller.enqueue(
      encoder.encode(`event: progress\ndata: ${JSON.stringify(data)}\n\n`)
    );
  };

  const sendArtifact = (content: string) => {
    // ì•„í‹°íŒ©íŠ¸ ì „ì†¡
    controller.enqueue(
      encoder.encode(`event: artifact\ndata: ${JSON.stringify({ content })}\n\n`)
    );
  };

  const close = () => {
    controller.close();
  };

  return { stream, sendProgress, sendArtifact, close };
}

// Step 1: Perplexity - 1ì°¨ ìë£Œ ìˆ˜ì§‘
async function perplexityDataCollection(
  query: string,
  depth: string,
  userId?: string
): Promise<string[]> {
  const apiKey = await getApiKey("perplexity", userId);

  const queryCount = depth === "quick" ? 2 : depth === "standard" ? 4 : 6;
  const queries = [
    `${query} - ìµœì‹  ë™í–¥ê³¼ íŠ¸ë Œë“œ`,
    `${query} - í†µê³„ ë°ì´í„°ì™€ ìˆ˜ì¹˜`,
    depth !== "quick" ? `${query} - ì‹¤ì œ ì‚¬ë¡€ì™€ ì˜ˆì‹œ` : null,
    depth !== "quick" ? `${query} - ì „ë¬¸ê°€ ì˜ê²¬ê³¼ ë¶„ì„` : null,
    depth === "deep" ? `${query} - ë¯¸ë˜ ì „ë§ê³¼ ì˜ˆì¸¡` : null,
    depth === "deep" ? `${query} - ê¸€ë¡œë²Œ ë¹„êµ ë¶„ì„` : null,
  ].filter(Boolean).slice(0, queryCount) as string[];

  if (!apiKey) {
    console.log("Perplexity API í‚¤ ì—†ìŒ");
    return queries.map(() => "");
  }

  const results: string[] = [];

  for (const q of queries) {
    try {
      const model = getModelWithKey("llama-3.1-sonar-large-128k-online", apiKey);
      const result = await generateText({
        model,
        prompt: `ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”:

"${q}"

í¬í•¨í•  ë‚´ìš©:
- í•µì‹¬ ê°œë…ê³¼ ì •ì˜
- ìµœì‹  í†µê³„ì™€ ìˆ˜ì¹˜ (ì¶œì²˜ ëª…ì‹œ)
- êµ¬ì²´ì ì¸ ì‚¬ë¡€
- ì „ë¬¸ê°€ ì˜ê²¬
- ê´€ë ¨ íŠ¸ë Œë“œ

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.`,
      });
      results.push(result.text);
    } catch (error) {
      console.error("Perplexity ê²€ìƒ‰ ì˜¤ë¥˜:", error);
      results.push("");
    }
  }

  return results;
}

// Step 2: OpenAI - ìë£Œ ê²€ì¦ ë° ë¦¬ì„œì¹˜ ê°œìš” ìƒì„±
async function openaiVerifyAndOutline(
  query: string,
  perplexityData: string[],
  depth: string,
  userId?: string
): Promise<{ outline: object; verifiedData: string }> {
  const apiKey = await getApiKey("openai", userId);
  if (!apiKey) throw new Error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤");

  const model = getModelWithKey("gpt-4o", apiKey);

  const combinedData = perplexityData
    .filter((d) => d)
    .map((d, i) => `## ìë£Œ ${i + 1}\n${d}`)
    .join("\n\n---\n\n");

  const sectionCount = depth === "quick" ? 3 : depth === "standard" ? 5 : 7;

  const result = await generateText({
    model,
    system: `ë‹¹ì‹ ì€ ë¦¬ì„œì¹˜ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìˆ˜ì§‘ëœ ìë£Œë¥¼ ê²€ì¦í•˜ê³  êµ¬ì¡°í™”ëœ ê°œìš”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.`,
    prompt: `## ì—°êµ¬ ì£¼ì œ
${query}

## ìˆ˜ì§‘ëœ ìë£Œ
${combinedData}

ìœ„ ìë£Œë¥¼ ë¶„ì„í•˜ê³  ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”:

{
  "outline": {
    "title": "ë³´ê³ ì„œ ì œëª©",
    "summary": "3ì¤„ ìš”ì•½",
    "sections": [
      {"title": "ì„¹ì…˜ ì œëª©", "keyPoints": ["í¬ì¸íŠ¸1", "í¬ì¸íŠ¸2"]},
      ...${sectionCount}ê°œ ì„¹ì…˜
    ],
    "keywords": ["í•µì‹¬í‚¤ì›Œë“œ1", "í•µì‹¬í‚¤ì›Œë“œ2", "í•µì‹¬í‚¤ì›Œë“œ3"]
  },
  "verifiedData": "ê²€ì¦ë˜ê³  ì •ë¦¬ëœ í•µì‹¬ ìë£Œ (ë§ˆí¬ë‹¤ìš´ í˜•ì‹)"
}

verifiedDataëŠ” ì¤‘ë³µ ì œê±°, ì‚¬ì‹¤ í™•ì¸, í•µì‹¬ ë‚´ìš© ì¶”ì¶œí•œ ê²°ê³¼ë¥¼ í¬í•¨í•˜ì„¸ìš”.`,
  });

  try {
    const jsonMatch = result.text.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0]);
    }
  } catch (e) {
    console.error("ê°œìš” íŒŒì‹± ì˜¤ë¥˜:", e);
  }

  return {
    outline: {
      title: query,
      summary: "ë¶„ì„ ì¤‘...",
      sections: [],
      keywords: [],
    },
    verifiedData: combinedData,
  };
}

// Step 3: Gemini - í¬ë¡¤ë§ ë° êµ¬ê¸€ ê²€ìƒ‰
async function geminiCrawlAndSearch(
  query: string,
  outline: any,
  userId?: string
): Promise<string> {
  const apiKey = await getApiKey("google", userId);

  if (!apiKey) {
    console.log("Gemini API í‚¤ ì—†ìŒ");
    return "";
  }

  try {
    const model = getModelWithKey("gemini-1.5-pro", apiKey);

    // ê° ì„¹ì…˜ë³„ ì¶”ê°€ ê²€ìƒ‰
    const searchQueries = outline.sections
      .slice(0, 3)
      .map((s: any) => `${query} ${s.title}`)
      .join(", ");

    const result = await generateText({
      model,
      prompt: `ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì¶”ê°€ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•´ì£¼ì„¸ìš”:

ì£¼ì œ: ${query}

ê²€ìƒ‰í•  ë‚´ìš©:
${searchQueries}

ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:
- ì›¹ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ìµœì‹  ì •ë³´
- ê´€ë ¨ ë‰´ìŠ¤ë‚˜ ë°œí‘œ
- ì¶”ê°€ í†µê³„ì™€ ë°ì´í„°
- êµ¬ì²´ì ì¸ ì‚¬ë¡€ ì—°êµ¬

ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.`,
    });

    return result.text;
  } catch (error) {
    console.error("Gemini ê²€ìƒ‰ ì˜¤ë¥˜:", error);
    return "";
  }
}

// Step 4: OpenAI - ìë£Œ ê²€ì¦ ë° ë³´ê³ ì„œ ì´ˆì•ˆ ì‘ì„±
async function openaiDraftReport(
  query: string,
  outline: any,
  verifiedData: string,
  geminiData: string,
  depth: string,
  userId?: string
): Promise<string> {
  const apiKey = await getApiKey("openai", userId);
  if (!apiKey) throw new Error("OpenAI API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤");

  const model = getModelWithKey("gpt-4o", apiKey);

  const lengthGuide = {
    quick: "1000-1500ì",
    standard: "2500-3500ì",
    deep: "5000ì ì´ìƒ",
  };

  const result = await generateText({
    model,
    system: `ë‹¹ì‹ ì€ ì „ë¬¸ ë¦¬ì„œì¹˜ ì‘ì„±ê°€ì…ë‹ˆë‹¤. ìˆ˜ì§‘ëœ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì²´ê³„ì ì¸ ë³´ê³ ì„œ ì´ˆì•ˆì„ ì‘ì„±í•©ë‹ˆë‹¤.

## ë³´ê³ ì„œ í˜•ì‹
ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”:
- # ì œëª©
- ## ì„¹ì…˜ ì œëª©
- ### ì†Œì œëª©
- **ê°•ì¡°**
- ëª©ë¡: - ë˜ëŠ” 1.
- > ì¸ìš©ë¬¸
- í†µê³„ëŠ” êµ¬ì²´ì  ìˆ˜ì¹˜ í¬í•¨`,
    prompt: `## ì—°êµ¬ ì£¼ì œ
${query}

## ë³´ê³ ì„œ ê°œìš”
ì œëª©: ${outline.title}
ìš”ì•½: ${outline.summary}
ì„¹ì…˜: ${outline.sections.map((s: any) => s.title).join(", ")}
í‚¤ì›Œë“œ: ${outline.keywords.join(", ")}

## ê²€ì¦ëœ 1ì°¨ ìë£Œ
${verifiedData}

## ì¶”ê°€ ê²€ìƒ‰ ìë£Œ (Gemini)
${geminiData}

---

ìœ„ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ${lengthGuide[depth as keyof typeof lengthGuide]} ë¶„ëŸ‰ì˜ ë³´ê³ ì„œ ì´ˆì•ˆì„ ì‘ì„±í•˜ì„¸ìš”.

êµ¬ì¡°:
${outline.sections.map((s: any, i: number) => `${i + 1}. ${s.title}\n   - ${s.keyPoints.join("\n   - ")}`).join("\n")}

ì´ˆì•ˆë§Œ ì‘ì„±í•˜ì„¸ìš”. ìµœì¢… í¸ì§‘ì€ ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ì§„í–‰ë©ë‹ˆë‹¤.`,
  });

  return result.text;
}

// Step 5: Claude - ìµœì¢… Narrative ì—­í•  (ë¦¬ì„œì¹˜ ë³´ê³ ì„œ ì™„ì„±)
async function claudeNarrative(
  query: string,
  draft: string,
  outline: any,
  userId?: string
): Promise<string> {
  const apiKey = await getApiKey("anthropic", userId);
  if (!apiKey) {
    console.log("Claude API í‚¤ ì—†ìŒ, ì´ˆì•ˆ ê·¸ëŒ€ë¡œ ë°˜í™˜");
    return draft;
  }

  try {
    const model = getModelWithKey("claude-sonnet-4-5-20250929", apiKey);

    const result = await generateText({
      model,
      system: `ë‹¹ì‹ ì€ ìµœê³ ì˜ ë¦¬ì„œì¹˜ í¸ì§‘ìì´ì ìŠ¤í† ë¦¬í…”ëŸ¬ì…ë‹ˆë‹¤.
ë³´ê³ ì„œ ì´ˆì•ˆì„ ì½ê¸° ì‰½ê³  ì„¤ë“ë ¥ ìˆëŠ” ìµœì¢… ë³´ê³ ì„œë¡œ ë‹¤ë“¬ìŠµë‹ˆë‹¤.

## ì—­í• 
1. ìì—°ìŠ¤ëŸ¬ìš´ íë¦„ê³¼ ë…¼ë¦¬ êµ¬ì„±
2. ëª…í™•í•˜ê³  ê°„ê²°í•œ ë¬¸ì¥ìœ¼ë¡œ ê°œì„ 
3. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ê°•ì¡°
4. ë…ì ê´€ì ì—ì„œ ê°€ë…ì„± í–¥ìƒ
5. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ìµœì í™”`,
      prompt: `## ì—°êµ¬ ì£¼ì œ
${query}

## ë³´ê³ ì„œ ê°œìš”
${outline.title}
${outline.summary}

## ë³´ê³ ì„œ ì´ˆì•ˆ
${draft}

---

ìœ„ ì´ˆì•ˆì„ ìµœì¢… ë³´ê³ ì„œë¡œ ë‹¤ë“¬ì–´ì£¼ì„¸ìš”.

ê°œì„  ì‚¬í•­:
1. ë„ì…ë¶€ë¥¼ ë” í¥ë¯¸ë¡­ê²Œ
2. ê° ì„¹ì…˜ ê°„ ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°
3. í•µì‹¬ ë©”ì‹œì§€ ëª…í™•í™”
4. ê²°ë¡ ì—ì„œ actionable insights ì œê³µ
5. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ ì™„ë²½ ì ìš© (ì œëª©, ê°•ì¡°, ëª©ë¡, ì¸ìš© ë“±)

ìµœì¢… ë³´ê³ ì„œë§Œ ì¶œë ¥í•˜ì„¸ìš”.`,
    });

    return result.text;
  } catch (error) {
    console.error("Claude í¸ì§‘ ì˜¤ë¥˜:", error);
    return draft;
  }
}

export async function POST(req: Request) {
  const session = await auth();
  const userId = session?.user?.id;

  try {
    const body: ResearchRequest = await req.json();
    const { query, depth = "standard" } = body;

    if (!query?.trim()) {
      return Response.json({ error: "ê²€ìƒ‰ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”" }, { status: 400 });
    }

    // Validate query for prompt injection
    let sanitizedQuery: string;
    try {
      sanitizedQuery = validatePrompt(query, { strict: true });
    } catch (error) {
      return Response.json(
        { error: "Your query contains patterns that could be harmful. Please rephrase your request." },
        { status: 400 }
      );
    }

    const { stream, sendProgress, sendArtifact, close } = createSSEStream();

    // ë¹„ë™ê¸° í˜‘ì—… ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
    (async () => {
      try {
        // === Step 1: Perplexity - 1ì°¨ ìë£Œ ìˆ˜ì§‘ ===
        sendProgress({
          stage: "perplexity",
          step: 1,
          totalSteps: 5,
          agent: "Perplexity",
          message: "ğŸ” Perplexityë¡œ 1ì°¨ ìë£Œ ìˆ˜ì§‘ ì¤‘...",
          progress: 5,
        });

        const queryCount = depth === "quick" ? 2 : depth === "standard" ? 4 : 6;
        const perplexityData = await perplexityDataCollection(sanitizedQuery, depth, userId);

        const successCount = perplexityData.filter((d) => d).length;
        sendProgress({
          stage: "perplexity",
          step: 1,
          totalSteps: 5,
          agent: "Perplexity",
          message: `âœ… Perplexity ìë£Œ ìˆ˜ì§‘ ì™„ë£Œ\n${successCount}/${queryCount}ê°œ ì¿¼ë¦¬ ê²€ìƒ‰ ì™„ë£Œ`,
          progress: 20,
        });

        // === Step 2: OpenAI - ìë£Œ ê²€ì¦ ë° ê°œìš” ìƒì„± ===
        sendProgress({
          stage: "openai-verify",
          step: 2,
          totalSteps: 5,
          agent: "GPT-4o",
          message: "ğŸ”¬ OpenAIë¡œ ìë£Œ ê²€ì¦ ë° ë¦¬ì„œì¹˜ ê°œìš” ìƒì„± ì¤‘...",
          progress: 25,
        });

        const { outline, verifiedData } = await openaiVerifyAndOutline(
          sanitizedQuery,
          perplexityData,
          depth,
          userId
        );

        sendProgress({
          stage: "openai-verify",
          step: 2,
          totalSteps: 5,
          agent: "GPT-4o",
          message: `âœ… OpenAI ê²€ì¦ ë° ê°œìš” ìƒì„± ì™„ë£Œ\n- ì„¹ì…˜: ${
            (outline as any).sections?.length || 0
          }ê°œ\n- í‚¤ì›Œë“œ: ${(outline as any).keywords?.join(", ") || ""}`,
          progress: 40,
          outline,
        });

        // === Step 3: Gemini - í¬ë¡¤ë§ ë° êµ¬ê¸€ ê²€ìƒ‰ ===
        sendProgress({
          stage: "gemini",
          step: 3,
          totalSteps: 5,
          agent: "Gemini 1.5 Pro",
          message: "ğŸŒ Geminië¡œ ì¶”ê°€ í¬ë¡¤ë§ ë° êµ¬ê¸€ ê²€ìƒ‰ ì¤‘...",
          progress: 45,
        });

        const geminiData = await geminiCrawlAndSearch(sanitizedQuery, outline, userId);

        sendProgress({
          stage: "gemini",
          step: 3,
          totalSteps: 5,
          agent: "Gemini 1.5 Pro",
          message: `âœ… Gemini ê²€ìƒ‰ ì™„ë£Œ\nì¶”ê°€ ìë£Œ ${geminiData ? "ìˆ˜ì§‘ ì„±ê³µ" : "ì—†ìŒ"}`,
          progress: 60,
        });

        // === Step 4: OpenAI - ë³´ê³ ì„œ ì´ˆì•ˆ ì‘ì„± ===
        sendProgress({
          stage: "openai-draft",
          step: 4,
          totalSteps: 5,
          agent: "GPT-4o",
          message: "ğŸ“ OpenAIë¡œ ë³´ê³ ì„œ ì´ˆì•ˆ ì‘ì„± ì¤‘...",
          progress: 65,
        });

        const draft = await openaiDraftReport(
          sanitizedQuery,
          outline,
          verifiedData,
          geminiData,
          depth,
          userId
        );

        sendProgress({
          stage: "openai-draft",
          step: 4,
          totalSteps: 5,
          agent: "GPT-4o",
          message: `âœ… OpenAI ì´ˆì•ˆ ì‘ì„± ì™„ë£Œ\n${draft.length}ì ë³´ê³ ì„œ ìƒì„±`,
          progress: 80,
        });

        // ì´ˆì•ˆì„ ì•„í‹°íŒ©íŠ¸ë¡œ ë¯¸ë¦¬ ì „ì†¡
        sendArtifact(draft);

        // === Step 5: Claude - ìµœì¢… Narrative ===
        sendProgress({
          stage: "claude",
          step: 5,
          totalSteps: 5,
          agent: "Claude 3.5 Sonnet",
          message: "âœ¨ Claudeë¡œ ìµœì¢… ë³´ê³ ì„œ í¸ì§‘ ë° Narrative ì‘ì„± ì¤‘...",
          progress: 85,
        });

        const finalReport = await claudeNarrative(sanitizedQuery, draft, outline, userId);

        sendProgress({
          stage: "complete",
          step: 5,
          totalSteps: 5,
          agent: "Complete",
          message: "âœ… ë¦¬ì„œì¹˜ ì™„ë£Œ!\n5ê°œ AI í˜‘ì—…ìœ¼ë¡œ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ",
          progress: 100,
        });

        // ìµœì¢… ë³´ê³ ì„œë¥¼ ì•„í‹°íŒ©íŠ¸ë¡œ ì „ì†¡
        sendArtifact(finalReport);
      } catch (error) {
        console.error("ë¦¬ì„œì¹˜ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜:", error);
        sendProgress({
          stage: "error",
          message: `âŒ ì˜¤ë¥˜: ${(error as Error).message}`,
          progress: 0,
        });
      } finally {
        close();
      }
    })();

    return new Response(stream, {
      headers: {
        "Content-Type": "text/event-stream",
        "Cache-Control": "no-cache",
        Connection: "keep-alive",
      },
    });
  } catch (error) {
    console.error("ë¦¬ì„œì¹˜ API ì˜¤ë¥˜:", error);
    return Response.json({ error: "ë¦¬ì„œì¹˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤" }, { status: 500 });
  }
}
