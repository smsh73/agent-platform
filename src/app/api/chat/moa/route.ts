import { generateText, streamText } from "ai";
import { auth } from "@/lib/auth";
import { getApiKey } from "@/lib/ai/get-api-key";
import { getModelWithKey, getProviderFromModel } from "@/lib/ai/providers";
import {
  AgentResponse,
  AnalysisResult,
  DEFAULT_MOA_CONFIG,
  MOA_PROMPTS,
} from "@/types/mixture-of-agents";

export const maxDuration = 180; // 3ë¶„ íƒ€ì„ì•„ì›ƒ

interface MoARequest {
  messages: { role: string; content: string }[];
  enableSearch?: boolean;
}

// ë³‘ë ¬ë¡œ ì—¬ëŸ¬ AI ëª¨ë¸ ì‹¤í–‰
async function runAgentsInParallel(
  prompt: string,
  userId?: string
): Promise<AgentResponse[]> {
  const agents = DEFAULT_MOA_CONFIG.agents;
  const startTime = Date.now();

  const promises = agents.map(async (agent) => {
    const agentStart = Date.now();
    try {
      const apiKey = await getApiKey(agent.provider, userId);
      if (!apiKey) {
        return {
          provider: agent.provider,
          model: agent.model,
          content: `[${agent.provider} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤]`,
          latency: Date.now() - agentStart,
        } as AgentResponse;
      }

      const model = getModelWithKey(agent.model, apiKey);
      const result = await generateText({
        model,
        prompt,
      });

      return {
        provider: agent.provider,
        model: agent.model,
        content: result.text,
        latency: Date.now() - agentStart,
        tokens: {
          input: result.usage?.inputTokens || 0,
          output: result.usage?.outputTokens || 0,
        },
      } as AgentResponse;
    } catch (error) {
      console.error(`${agent.provider} ì—ëŸ¬:`, error);
      return {
        provider: agent.provider,
        model: agent.model,
        content: `[${agent.provider} ì˜¤ë¥˜: ${(error as Error).message}]`,
        latency: Date.now() - agentStart,
      } as AgentResponse;
    }
  });

  return Promise.all(promises);
}

// Perplexityë¡œ ìµœì‹  ì •ë³´ ê²€ìƒ‰
async function searchWithPerplexity(
  query: string,
  userId?: string
): Promise<string | null> {
  try {
    const apiKey = await getApiKey("perplexity", userId);
    if (!apiKey) return null;

    const model = getModelWithKey(
      DEFAULT_MOA_CONFIG.searcher.model,
      apiKey
    );

    const result = await generateText({
      model,
      prompt: `ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•´ ìµœì‹  ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë‹µë³€í•´ì£¼ì„¸ìš”: ${query}`,
    });

    return result.text;
  } catch (error) {
    console.error("Perplexity ê²€ìƒ‰ ì˜¤ë¥˜:", error);
    return null;
  }
}

// ê²€ìƒ‰ì´ í•„ìš”í•œì§€ íŒë‹¨
async function needsSearch(
  prompt: string,
  userId?: string
): Promise<boolean> {
  try {
    const apiKey = await getApiKey("openai", userId);
    if (!apiKey) return false;

    const model = getModelWithKey("gpt-4o-mini", apiKey);
    const result = await generateText({
      model,
      system: MOA_PROMPTS.needsSearch,
      prompt,
    });

    return result.text.trim().toUpperCase() === "YES";
  } catch {
    return false;
  }
}

// Orchestrator: ì‘ë‹µ ë¶„ì„
async function analyzeResponses(
  prompt: string,
  responses: AgentResponse[],
  searchResults: string | null,
  userId?: string
): Promise<AnalysisResult> {
  const apiKey = await getApiKey(
    DEFAULT_MOA_CONFIG.orchestrator.provider,
    userId
  );

  if (!apiKey) {
    throw new Error("Orchestrator API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤");
  }

  const model = getModelWithKey(
    DEFAULT_MOA_CONFIG.orchestrator.model,
    apiKey
  );

  const responsesText = responses
    .map(
      (r) => `## ${r.provider.toUpperCase()} (${r.model})
${r.content}`
    )
    .join("\n\n---\n\n");

  const analysisPrompt = `# ì‚¬ìš©ì ì§ˆë¬¸
${prompt}

${searchResults ? `# ìµœì‹  ê²€ìƒ‰ ê²°ê³¼ (Perplexity)
${searchResults}

---

` : ""}# AI ëª¨ë¸ ì‘ë‹µë“¤

${responsesText}

---

ìœ„ ì‘ë‹µë“¤ì„ ë¶„ì„í•˜ê³  ê° ì‘ë‹µì˜ ìµœê³  ë¶€ë¶„ì„ ì„ ë³„í•´ì£¼ì„¸ìš”.`;

  const result = await generateText({
    model,
    system: MOA_PROMPTS.orchestrator,
    prompt: analysisPrompt,
  });

  try {
    const jsonMatch = result.text.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0]);
    }
  } catch (e) {
    console.error("ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì˜¤ë¥˜:", e);
  }

  // ê¸°ë³¸ ë¶„ì„ ê²°ê³¼ ë°˜í™˜
  return {
    bestParts: responses.map((r) => ({
      provider: r.provider,
      section: "ì „ì²´",
      reason: "ìë™ ë¶„ì„",
      content: r.content.substring(0, 500),
    })),
    rankings: responses.map((r, i) => ({
      provider: r.provider,
      score: 80 - i * 5,
      strengths: ["ì‘ë‹µ ìƒì„±ë¨"],
      weaknesses: [],
    })),
  };
}

// Narrator: ìµœì¢… ë‹µë³€ í•©ì„±
async function synthesizeFinalAnswer(
  prompt: string,
  analysis: AnalysisResult,
  searchResults: string | null,
  userId?: string
): Promise<string> {
  const apiKey = await getApiKey(
    DEFAULT_MOA_CONFIG.narrator.provider,
    userId
  );

  if (!apiKey) {
    throw new Error("Narrator API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤");
  }

  const model = getModelWithKey(DEFAULT_MOA_CONFIG.narrator.model, apiKey);

  const bestPartsText = analysis.bestParts
    .map(
      (p) => `### ${p.provider} - ${p.section}
**ì„ ì • ì´ìœ **: ${p.reason}
**ë‚´ìš©**:
${p.content}`
    )
    .join("\n\n");

  const synthesisPrompt = `# ì‚¬ìš©ì ì§ˆë¬¸
${prompt}

${searchResults ? `# ìµœì‹  ì •ë³´ (Perplexity ê²€ìƒ‰)
${searchResults}

` : ""}# ë¶„ì„ì—ì„œ ì„ ë³„ëœ ìµœê³ ì˜ íŒŒíŠ¸ë“¤

${bestPartsText}

---

ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì™„ë²½í•œ ìµœì¢… ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.`;

  const result = await generateText({
    model,
    system: MOA_PROMPTS.narrator,
    prompt: synthesisPrompt,
  });

  return result.text;
}

export async function POST(req: Request) {
  const startTime = Date.now();

  try {
    const session = await auth();
    const body: MoARequest = await req.json();
    const { messages, enableSearch = true } = body;

    const lastMessage = messages[messages.length - 1];
    if (!lastMessage || lastMessage.role !== "user") {
      return Response.json(
        { error: "ì‚¬ìš©ì ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤" },
        { status: 400 }
      );
    }

    const userPrompt = lastMessage.content;
    const userId = session?.user?.id;

    // 1. ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ íŒë‹¨ & ê²€ìƒ‰ ì‹¤í–‰
    let searchResults: string | null = null;
    if (enableSearch) {
      const shouldSearch = await needsSearch(userPrompt, userId);
      if (shouldSearch) {
        console.log("ğŸ” Perplexity ê²€ìƒ‰ ì‹¤í–‰...");
        searchResults = await searchWithPerplexity(userPrompt, userId);
      }
    }

    // 2. ëª¨ë“  ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰
    console.log("ğŸ¤– ì—ì´ì „íŠ¸ ë³‘ë ¬ ì‹¤í–‰...");
    const agentResponses = await runAgentsInParallel(userPrompt, userId);

    // 3. Orchestrator: ì‘ë‹µ ë¶„ì„
    console.log("ğŸ¯ Orchestrator ë¶„ì„ ì¤‘...");
    const analysis = await analyzeResponses(
      userPrompt,
      agentResponses,
      searchResults,
      userId
    );

    // 4. Narrator: ìµœì¢… ë‹µë³€ í•©ì„±
    console.log("âœï¸ Narrator í•©ì„± ì¤‘...");
    const finalAnswer = await synthesizeFinalAnswer(
      userPrompt,
      analysis,
      searchResults,
      userId
    );

    const totalLatency = Date.now() - startTime;

    // ê²°ê³¼ ë°˜í™˜
    return Response.json({
      finalAnswer,
      agentResponses,
      analysis,
      searchResults,
      totalLatency,
      orchestrator: `${DEFAULT_MOA_CONFIG.orchestrator.provider}/${DEFAULT_MOA_CONFIG.orchestrator.model}`,
      narrator: `${DEFAULT_MOA_CONFIG.narrator.provider}/${DEFAULT_MOA_CONFIG.narrator.model}`,
    });
  } catch (error) {
    console.error("MoA ì˜¤ë¥˜:", error);
    return Response.json(
      { error: (error as Error).message || "Mixture of Agents ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜" },
      { status: 500 }
    );
  }
}

// ìŠ¤íŠ¸ë¦¬ë° ë²„ì „ (ì§„í–‰ ìƒí™© í‘œì‹œ)
export async function OPTIONS(req: Request) {
  return Response.json({
    config: DEFAULT_MOA_CONFIG,
    prompts: Object.keys(MOA_PROMPTS),
  });
}
